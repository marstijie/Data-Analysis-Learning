所有项目均以学习为目的，不用于任何商用
在这里我会总结一下学习爬虫过程中的收获（持续更新...）
1. 讲讲爬虫常见套路
2. 梳理各类网站的爬取方法；  
分析网页：打开目标网页查看网页源代码，找到目标URL  
A.一般的网页信息就在网页源代码中，我们只要找到网页源代码，根据节点就能提取到信息。  
B.部分网站的数据是通过调用 API接口 来展示的，在爬取这类网站时，我们要分析信息存储地址，找到对应的API接口去请求数据  
C.还有一些网页会使用动态加载技术，将信息存储在JavaScript文件中。 在爬取这类网站中的内容时，我们要在开发者模式中，找到文件类型为script，数据格式为JSON格式，请求文件链接解析JSON数据。  
请求网页：向网页发送请求  
A.请求网页需要导入 requests模块 ，并调用该模块中的 get() 函数,少数网站我们直接使用requests.get()请求URL获取内容  
B.但大部分网站都设有反爬虫机制，所以请求网页时需要设置请求头参数，常见的在headers中以字典的格式带上User-Agent即可  
C.还有许多网页设有其他反爬虫措施，不仅检查User-Agent信息还会检查请求头中的Cookie信息，用于辨别用户的身份  
提取数据：按照节点提取信息  
A.拿到网页源代码后，常见的HTML格式的网页需要导入bs4模块来解析网页内容  
B.有时我们获取到的数据是乱码的，这是由于网页编码(对网页转码)和字体反爬虫等原因造成的(对字体进行解码再提取内容)  
C.当我们从JavaScript文件中提取信息时，由于该文件中的内容使用JSON格式存储数据，这时需要根据JSON格式来提取内容  
保存分析：将数据保存下来或做可视化操作  
A.使用with...as语句配合open()函数来保存为txt文件  
B.使用pandas模块将数据写入到Excel文档中  
3. 总结反爬虫知识点  
a.string提取单个节点中的文本内容，若存在多个节点就会输出None
b.text即可提取单个节点，也可提取多个节点信息，以字符串格式输出
c.contents提取多个节点信息，并以列表形式输出  

![img.png](img.png)
